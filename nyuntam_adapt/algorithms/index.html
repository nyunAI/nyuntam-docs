
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://zero.nyunai.com/docs/nyuntam_adapt/algorithms/">
      
      
        <link rel="prev" href="../">
      
      
        <link rel="next" href="../../nyuntam_vision/">
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.5.17">
    
    
      
        <title>Algorithms - Nyun Zero</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.bcfcd587.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
      
        <meta  property="og:type"  content="website" >
      
        <meta  property="og:title"  content="Algorithms - Nyun Zero" >
      
        <meta  property="og:description"  content="None" >
      
        <meta  property="og:image"  content="https://zero.nyunai.com/docs/assets/images/social/nyuntam_adapt/algorithms.png" >
      
        <meta  property="og:image:type"  content="image/png" >
      
        <meta  property="og:image:width"  content="1200" >
      
        <meta  property="og:image:height"  content="630" >
      
        <meta  property="og:url"  content="https://zero.nyunai.com/docs/nyuntam_adapt/algorithms/" >
      
        <meta  name="twitter:card"  content="summary_large_image" >
      
        <meta  name="twitter:title"  content="Algorithms - Nyun Zero" >
      
        <meta  name="twitter:description"  content="None" >
      
        <meta  name="twitter:image"  content="https://zero.nyunai.com/docs/assets/images/social/nyuntam_adapt/algorithms.png" >
      
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="slate" data-md-color-primary="teal" data-md-color-accent="teal">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#algorithms" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="https://www.nyunai.com" title="Nyun Zero" class="md-header__button md-logo" aria-label="Nyun Zero" data-md-component="logo">
      
  <img src="../../assets/nyun.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Nyun Zero
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Algorithms
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="teal" data-md-color-accent="teal"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="teal" data-md-color-accent="teal"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



  

<nav class="md-nav md-nav--primary md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="https://www.nyunai.com" title="Nyun Zero" class="md-nav__button md-logo" aria-label="Nyun Zero" data-md-component="logo">
      
  <img src="../../assets/nyun.png" alt="logo">

    </a>
    Nyun Zero
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../dataset/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Dataset Import
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../support/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Support Grid
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Nyuntam Adapt
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4" id="__nav_4_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Nyuntam Adapt
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Algorithms
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Algorithms
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#overview" class="md-nav__link">
    <span class="md-ellipsis">
      Overview
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Overview">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#lora-low-rank-adaptation" class="md-nav__link">
    <span class="md-ellipsis">
      LoRA (Low Rank Adaptation)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ssf-scaling-and-shifting-your-features" class="md-nav__link">
    <span class="md-ellipsis">
      SSF (Scaling and Shifting your Features)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dora-weight-decomposed-low-rank-adaptation" class="md-nav__link">
    <span class="md-ellipsis">
      DoRA (Weight-Decomposed Low-Rank Adaptation)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#qlora-quantized-low-rank-adaptation" class="md-nav__link">
    <span class="md-ellipsis">
      QLoRA (Quantized Low Rank Adaptation)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#qdora-weight-decomposed-low-rank-adaptation" class="md-nav__link">
    <span class="md-ellipsis">
      QDoRA (Weight-Decomposed Low-Rank Adaptation)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#q-ssf-quantized-ssf" class="md-nav__link">
    <span class="md-ellipsis">
      Q-SSF (Quantized SSF)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Q-SSF (Quantized SSF)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#quantization-parameters-for-qloraqdoraq-ssf" class="md-nav__link">
    <span class="md-ellipsis">
      Quantization Parameters for QLoRA/QDoRA/Q-SSF
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#full-fine-tuning" class="md-nav__link">
    <span class="md-ellipsis">
      Full Fine-tuning
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#last-layer-tuning" class="md-nav__link">
    <span class="md-ellipsis">
      Last Layer Tuning
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#common-training-parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Common Training Parameters
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ddp-arguments" class="md-nav__link">
    <span class="md-ellipsis">
      DDP arguments
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#fsdp-arguments" class="md-nav__link">
    <span class="md-ellipsis">
      FSDP arguments
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#text-generation" class="md-nav__link">
    <span class="md-ellipsis">
      Text Generation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#text-classification" class="md-nav__link">
    <span class="md-ellipsis">
      Text Classification
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#summarization" class="md-nav__link">
    <span class="md-ellipsis">
      Summarization
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#translation" class="md-nav__link">
    <span class="md-ellipsis">
      Translation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#question-answering" class="md-nav__link">
    <span class="md-ellipsis">
      Question Answering
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#image-classification" class="md-nav__link">
    <span class="md-ellipsis">
      Image Classification
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#object-detection" class="md-nav__link">
    <span class="md-ellipsis">
      Object Detection
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#instance-segmentation" class="md-nav__link">
    <span class="md-ellipsis">
      Instance Segmentation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pose-detection" class="md-nav__link">
    <span class="md-ellipsis">
      Pose Detection
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_5" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../nyuntam_vision/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Nyuntam Vision
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5" id="__nav_5_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            Nyuntam Vision
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../nyuntam_vision/algorithms/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Algorithms
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_6" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../nyuntam_text_generation/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Nyuntam Text Generation
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_6" id="__nav_6_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            Nyuntam Text Generation
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../nyuntam_text_generation/algorithms/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Algorithms
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_7" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../examples/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Examples
  </span>
  

            </a>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            Examples
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="algorithms">Algorithms</h1>
<h2 id="overview">Overview</h2>
<p>nyuntam_adapt currently supports the following tasks - </p>
<ul>
<li><a href="#text-generation">Text Generation</a></li>
<li><a href="#text-classification">Text Classification</a></li>
<li><a href="#summarization">Summarization</a></li>
<li><a href="#translation">Translation</a></li>
<li><a href="#question-answering">Question Answering</a></li>
<li><a href="#image-classification">Image Classification</a></li>
<li><a href="#object-detection">Object Detection</a></li>
<li><a href="#instance-segmentation">Instance Segmentation</a></li>
<li><a href="#pose-detection">Pose Detection</a></li>
</ul>
<p>The following techniques are supported to adapt any model for the above mentioned tasks - </p>
<ul>
<li><a href="#lora-low-rank-adaptation">LoRA</a></li>
<li><a href="#ssf-scaling-and-shifting-your-features">SSF</a></li>
<li><a href="#dora-weight-decomposed-low-rank-adaptation">DoRA</a></li>
<li><a href="#qlora-quantized-low-rank-adaptation">QLoRA (4-bit and 8-bit)</a></li>
<li><a href="#qdora-weight-decomposed-low-rank-adaptation">QDoRA (4-bit and 8-bit)</a></li>
<li><a href="#q-ssf-quantized-ssf">QSSF (4-bit)</a></li>
</ul>
<h3 id="lora-low-rank-adaptation">LoRA (Low Rank Adaptation)</h3>
<p>LoRA is a Parameter-Efficient Fine-Tuning (PEFT) technique that optimizes AI models by introducing low-rank matrices to adjust the weights of pre-trained neural networks. This approach allows for significant improvements in model performance with minimal additional parameters, making it an efficient method for customizing AI models for specific tasks without the need for extensive retraining or computational resources.</p>
<p>Argument : <strong><em>method = "LoRA"</em></strong></p>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Value (Datatype)</th>
<th>Default Value</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>r</code></td>
<td>int</td>
<td>8</td>
<td>Rank of the low-rank approximation.</td>
</tr>
<tr>
<td><code>alpha</code></td>
<td>int</td>
<td>16</td>
<td>Scaling factor for LoRA adjustments.</td>
</tr>
<tr>
<td><code>dropout</code></td>
<td>float</td>
<td>0.1</td>
<td>Dropout rate for regularization.</td>
</tr>
<tr>
<td><code>target_modules</code></td>
<td></td>
<td></td>
<td>Modules within the model targeted for tuning.</td>
</tr>
<tr>
<td><code>fan_in_fan_out</code></td>
<td>bool</td>
<td>False</td>
<td>Whether to adjust initialization based on fan-in/fan-out.</td>
</tr>
<tr>
<td><code>init_lora_weights</code></td>
<td>bool</td>
<td>True</td>
<td>Initializes LoRA weights if set to True.</td>
</tr>
</tbody>
</table>
<h3 id="ssf-scaling-and-shifting-your-features">SSF (Scaling and Shifting your Features)</h3>
<p>SSF adjusts the scale (multiplication) and shift (addition) of features within a neural network to better adapt the model to specific tasks or datasets. By applying these simple yet effective transformations, SSF aims to enhance model performance without the need for extensive retraining or adding a significant number of parameters. This technique is particularly useful for fine-tuning pre-trained models in a more resource-efficient manner, allowing for targeted improvements with minimal computational cost.</p>
<p>Argument : <strong><em>method = "SSF"</em></strong></p>
<h3 id="dora-weight-decomposed-low-rank-adaptation">DoRA (Weight-Decomposed Low-Rank Adaptation)</h3>
<p>DoRA decomposes the pre-trained weight into two components, magnitude and direction, for fine-tuning, specifically employing LoRA for directional updates to efficiently minimize the number of trainable parameters. DoRA enhances both the learning capacity and training stability of LoRA while avoiding any additional inference overhead.</p>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Datatype</th>
<th>Default Value</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>r</code></td>
<td>integer</td>
<td>16</td>
<td>Rank of the low-rank approximation.</td>
</tr>
<tr>
<td><code>alpha</code></td>
<td>integer</td>
<td>8</td>
<td>Scaling factor for LoRA adjustments.</td>
</tr>
<tr>
<td><code>dropout</code></td>
<td>float</td>
<td>0.1</td>
<td>Dropout rate for regularization.</td>
</tr>
<tr>
<td><code>target_modules</code></td>
<td>list</td>
<td></td>
<td>The names of the layers for which peft modules will be created</td>
</tr>
<tr>
<td><code>fan_in_fan_out</code></td>
<td>boolean</td>
<td>False</td>
<td>Initializes DoRA weights if set to True.</td>
</tr>
</tbody>
</table>
<p>Argument : <strong><em>method = "DoRA"</em></strong></p>
<h3 id="qlora-quantized-low-rank-adaptation">QLoRA (Quantized Low Rank Adaptation)</h3>
<p>QLoRA (Quantized Low-Rank Adaptation) is a sophisticated Parameter-Efficient Fine-Tuning (PEFT) technique designed to enhance the adaptability and efficiency of pre-trained AI models with minimal computational overhead. The weight matrices of the original model are frozen and quantized thus reducing the memory footprint of the original model. QLoRA is particularly useful in scenarios where computational resources are limited, offering a balance between model adaptability, performance, and resource efficiency.</p>
<p>Arguments : <ul>
     <li><strong><em>method = "LoRA"</em></strong></li>
     <li><strong><em>load_in_4bit = "True" (for 4 bit quantization)</em></strong></li>
     <li><strong><em>load_in_8bit = "True" (for 8 bit quantization)</em></strong></li></ul></p>
<h3 id="qdora-weight-decomposed-low-rank-adaptation">QDoRA (Weight-Decomposed Low-Rank Adaptation)</h3>
<p>QDoRA (Weight-Decomposed Low-Rank Adaptation) is a sophisticated Parameter-Efficient Fine-Tuning (PEFT) technique designed to enhance the adaptability and efficiency of pre-trained AI models with minimal computational overhead.  QDoRA is particularly useful in scenarios where computational resources are limited, offering a balance between model adaptability, performance, and resource efficiency.</p>
<p>Arguments : <ul>
     <li><strong><em>method = "DoRA"</em></strong></li>
     <li><strong><em>load_in_4bit = "True" (for 4 bit quantization)</em></strong></li>
     <li><strong><em>load_in_8bit = "True" (for 8 bit quantization)</em></strong></li></ul></p>
<h3 id="q-ssf-quantized-ssf">Q-SSF (Quantized SSF)</h3>
<p>Quantized SSF applies quantizes the frozen model weights. The SSF modules are trained, enhancing model efficiency with minimal fidelity loss. This approach reduces memory and computational demands, ideal for resource-constrained environments, maintaining accuracy while improving performance.</p>
<p>Arguments : <ul>
     <li><strong><em>method = "SSF"</em></strong></li>
     <li><strong><em>load_in_4bit = "True" (for 4 bit quantization)</em></strong></li>
     <li><strong><em>load_in_8bit = "True" (for 8 bit quantization)</em></strong></li></ul></p>
<h4 id="quantization-parameters-for-qloraqdoraq-ssf">Quantization Parameters for QLoRA/QDoRA/Q-SSF</h4>
<p>Model Quantization is achieved via BitsandBytes module.</p>
<p><strong>4 bit Quantization</strong></p>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Datatype</th>
<th>Default Value</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>load_in_4bit</code></td>
<td>bool</td>
<td>True</td>
<td>Load model in 4-bit precision.</td>
</tr>
<tr>
<td><code>bnb_4bit_compute_dtype</code></td>
<td>str</td>
<td>'float16'</td>
<td>Compute data type in 4-bit mode.</td>
</tr>
<tr>
<td><code>bnb_4bit_quant_type</code></td>
<td>str</td>
<td>'nf4'</td>
<td>Quantization type for 4-bit precision.</td>
</tr>
<tr>
<td><code>bnb_4bit_use_double_quant</code></td>
<td>bool</td>
<td>False</td>
<td>Use double quantization in 4-bit mode.</td>
</tr>
</tbody>
</table>
<p><strong>8 bit Quantization</strong></p>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Datatype</th>
<th>Default Value</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>load_in_8bit</code></td>
<td>bool</td>
<td>False</td>
<td>Load model in 8-bit precision (only for float16/bfloat16 weights).</td>
</tr>
<tr>
<td><code>llm_int8_threshold</code></td>
<td>float</td>
<td>6.0</td>
<td>Threshold for LLM int8 quantization.</td>
</tr>
<tr>
<td><code>llm_int8_skip_modules</code></td>
<td></td>
<td></td>
<td>Modules to skip during LLM int8 quantization.</td>
</tr>
<tr>
<td><code>llm_int8_enable_fp32_cpu_offload</code></td>
<td>bool</td>
<td>False</td>
<td>Enable FP32 offload to CPU in int8 mode.</td>
</tr>
<tr>
<td><code>llm_int8_has_fp16_weight</code></td>
<td>bool</td>
<td>False</td>
<td>Whether the model has fp16/bfloat16 weights</td>
</tr>
</tbody>
</table>
<h3 id="full-fine-tuning">Full Fine-tuning</h3>
<p>This method updates all parameters of a neural network. This method is generally inefficient to run as it uses a lot of computing power to update all parameters of the given model. </p>
<p>Arguments : <ul>
     <li><strong><em>FULL_FINE_TUNING = "True"</em></strong></li>
     </ul></p>
<h3 id="last-layer-tuning">Last Layer Tuning</h3>
<p>Tuning the last layer is a popular technique in which all the layers of a model, except the last few layers are frozen i.e. their gradients are not updated during training. This method is generally used while finetuning a model trained on a huge generalized dataset (Imagenet) for downstream tasks. 
Arguments : <ul>
     <li><strong><em>LAST_LAYER_TUNING = "True"</em></strong></li>
     </ul></p>
<p><strong>*NOTE</strong> :<ul><li><a href="#full-fine-tuning">Full Fine Tuning</a> should be used without any PEFT methods.</li><li><a href="#last-layer-tuning">Last Layer Tuning</a> should be set to "True" while using any PEFT method.</li> </ul></p>
<h2 id="common-training-parameters">Common Training Parameters</h2>
<p>The wide variety of tasks and algorithms supported in nyuntam_adapt have several parameters that are common across all tasks/algorithms and some parameters that are specific to a particular task/algorithm</p>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Datatype</th>
<th>Default Value</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>DO_TRAIN</code></td>
<td>bool</td>
<td>true</td>
<td>Flag indicating whether to perform training</td>
</tr>
<tr>
<td><code>DO_EVAL</code></td>
<td>bool</td>
<td>true</td>
<td>Flag indicating whether to perform evaluation</td>
</tr>
<tr>
<td><code>NUM_WORKERS</code></td>
<td>int</td>
<td>4</td>
<td>Number of worker processes for data loading</td>
</tr>
<tr>
<td><code>BATCH_SIZE</code></td>
<td>int</td>
<td>16</td>
<td>Batch size for training</td>
</tr>
<tr>
<td><code>EPOCHS</code></td>
<td>int</td>
<td>2</td>
<td>Number of epochs for training</td>
</tr>
<tr>
<td><code>OPTIMIZER</code></td>
<td>str</td>
<td>adamw_torch</td>
<td>Optimization algorithm (sgd,adamw_torch,paged_adamw_32bit)</td>
</tr>
<tr>
<td><code>LR</code></td>
<td>float</td>
<td>1e-4</td>
<td>Learning rate</td>
</tr>
<tr>
<td><code>SCHEDULER_TYPE</code></td>
<td>str</td>
<td>linear</td>
<td>Type of learning rate scheduler(linear,constant) <strong>Supported Schedulers :</strong> <ul><li>Object deteciton, Instance Segmentation, Pose Detection - <ul><li>CosineAnnealingLR</li> <li>LinearLR</li> <li>MultiStepLR</li> </li></ul><li> NLP Tasks, Image Classification - All huggingface schedulers</td>
</tr>
<tr>
<td><code>WEIGHT_DECAY</code></td>
<td>float</td>
<td>0.0</td>
<td>Weight decay for optimization</td>
</tr>
<tr>
<td><code>BETA1</code></td>
<td>float</td>
<td>0.9</td>
<td>Beta1 parameter for Adam optimizer</td>
</tr>
<tr>
<td><code>BETA2</code></td>
<td>float</td>
<td>0.999</td>
<td>Beta2 parameter for Adam optimizer</td>
</tr>
<tr>
<td><code>ADAM_EPS</code></td>
<td>float</td>
<td>1e-8</td>
<td>Epsilon value for Adam optimizer</td>
</tr>
<tr>
<td><code>INTERVAL</code></td>
<td>str</td>
<td>epoch</td>
<td>Interval type for checkpointing (e.g., epoch)</td>
</tr>
<tr>
<td><code>INTERVAL_STEPS</code></td>
<td>int</td>
<td>100</td>
<td>Steps interval for checkpointing</td>
</tr>
<tr>
<td><code>NO_OF_CHECKPOINTS</code></td>
<td>int</td>
<td>5</td>
<td>Number of checkpoints to save during training</td>
</tr>
<tr>
<td><code>FP16</code></td>
<td>bool</td>
<td>false</td>
<td>Flag indicating whether to use FP16 precision</td>
</tr>
<tr>
<td><code>RESUME_FROM_CHECKPOINT</code></td>
<td>bool</td>
<td>false</td>
<td>Flag indicating whether to resume from a checkpoint</td>
</tr>
<tr>
<td><code>GRADIENT_ACCUMULATION_STEPS</code></td>
<td>int</td>
<td>1</td>
<td>Number of steps to accumulate gradients</td>
</tr>
<tr>
<td><code>GRADIENT_CHECKPOINTING</code></td>
<td>bool</td>
<td>false</td>
<td>Flag indicating whether to use gradient checkpointing</td>
</tr>
<tr>
<td><code>SAVE_METHOD</code></td>
<td>string</td>
<td>'state_dict'</td>
<td>The method in which the model will be saved (Values - 'full_torch_model' : Saves the model as a .pt file in full precision, 'state_dict' : Saves the model state dictionary,  'safetensors' : Saves the model weights as safetensors (Advisable for huggingface models) ,'save_pretrained':saves the model as a folder using huggingface's save_pretrained method (Only supporte for huggingface models.)  )</td>
</tr>
</tbody>
</table>
<h2 id="ddp-arguments">DDP arguments</h2>
<p>DistributedDataParallel (DDP) implements data parallelism at the module level which can run across multiple machines. The recommended way to run adaption for a model with DDP is to use the following parameters :</p>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Data Type</th>
<th>Default Value</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>DDP</code></td>
<td>bool</td>
<td>True</td>
<td>A boolean indicating whether DDP is enabled or not.</td>
</tr>
<tr>
<td><code>num_nodes</code></td>
<td>int</td>
<td>1</td>
<td>An integer refering to the number of nodes used for DDP training</td>
</tr>
</tbody>
</table>
<h2 id="fsdp-arguments">FSDP arguments</h2>
<p>Training AI models at a large scale is a challenging task that requires a lot of compute power and resources. It also comes with considerable engineering complexity to handle the training of these very large models. To address this Fully Sharded Data Parallel (FSDP) comes inbuilt with nyuntam-adapt. When training with FSDP, the GPU memory footprint is smaller than when training with DDP across all workers. This makes the training of some very large models feasible by allowing larger models or batch sizes to fit on device. This comes with the cost of increased communication volume. The communication overhead is reduced by internal optimizations like overlapping communication and computation.</p>
<table>
<thead>
<tr>
<th>Parameter Name</th>
<th>Data Type</th>
<th>Default Value</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>FSDP</code></td>
<td>Bool</td>
<td>True</td>
<td>Boolean indicating whether FSDP is enabled or not.</td>
</tr>
<tr>
<td><code>compute_environment</code></td>
<td>String</td>
<td>LOCAL_MACHINE</td>
<td>Specifies the environment where the computation runs.</td>
</tr>
<tr>
<td><code>debug</code></td>
<td>Boolean</td>
<td>false</td>
<td>Indicates whether debugging is enabled.</td>
</tr>
<tr>
<td><code>distributed_type</code></td>
<td>String</td>
<td>FSDP</td>
<td>Defines the type of distributed training.</td>
</tr>
<tr>
<td><code>downcast_bf16</code></td>
<td>String</td>
<td>'no'</td>
<td>Controls downcasting to bf16 precision.</td>
</tr>
<tr>
<td><code>fsdp_auto_wrap_policy</code></td>
<td>String</td>
<td>TRANSFORMER_BASED_WRAP</td>
<td>Auto-wrap policy for FSDP.</td>
</tr>
<tr>
<td><code>fsdp_backward_prefetch_policy</code></td>
<td>String</td>
<td>BACKWARD_PRE</td>
<td>Prefetch policy during FSDP backward pass.</td>
</tr>
<tr>
<td><code>fsdp_forward_prefetch</code></td>
<td>Boolean</td>
<td>false</td>
<td>Indicates if forward prefetching is enabled.</td>
</tr>
<tr>
<td><code>fsdp_cpu_ram_efficient_loading</code></td>
<td>Boolean</td>
<td>true</td>
<td>Enables efficient loading into CPU RAM.</td>
</tr>
<tr>
<td><code>fsdp_offload_params</code></td>
<td>Boolean</td>
<td>false</td>
<td>Indicates if parameters are offloaded.</td>
</tr>
<tr>
<td><code>fsdp_sharding_strategy</code></td>
<td>String</td>
<td>FULL_SHARD</td>
<td>Defines the FSDP sharding strategy.</td>
</tr>
<tr>
<td><code>fsdp_state_dict_type</code></td>
<td>String</td>
<td>SHARDED_STATE_DICT</td>
<td>Type of state dictionary used in FSDP.</td>
</tr>
<tr>
<td><code>fsdp_sync_module_states</code></td>
<td>Boolean</td>
<td>true</td>
<td>Synchronizes module states across processes.</td>
</tr>
<tr>
<td><code>fsdp_use_orig_params</code></td>
<td>Boolean</td>
<td>true</td>
<td>Indicates if original parameters are used.</td>
</tr>
<tr>
<td><code>machine_rank</code></td>
<td>Integer</td>
<td>0</td>
<td>Rank of the machine in the distributed setup.</td>
</tr>
<tr>
<td><code>main_training_function</code></td>
<td>String</td>
<td>main</td>
<td>Name of the main training function to run.</td>
</tr>
<tr>
<td><code>mixed_precision</code></td>
<td>String</td>
<td>bf16</td>
<td>Specifies the mixed precision type.</td>
</tr>
<tr>
<td><code>num_machines</code></td>
<td>Integer</td>
<td>1</td>
<td>Number of machines used in training.</td>
</tr>
<tr>
<td><code>num_processes</code></td>
<td>Integer</td>
<td>2</td>
<td>Number of processes per machine.</td>
</tr>
<tr>
<td><code>rdzv_backend</code></td>
<td>String</td>
<td>static</td>
<td>Rendezvous backend used for distributed training.</td>
</tr>
<tr>
<td><code>same_network</code></td>
<td>Boolean</td>
<td>true</td>
<td>Indicates if machines are on the same network.</td>
</tr>
<tr>
<td><code>tpu_env</code></td>
<td>Array</td>
<td>[]</td>
<td>Environment variables for TPU.</td>
</tr>
<tr>
<td><code>tpu_use_cluster</code></td>
<td>Boolean</td>
<td>false</td>
<td>Indicates if TPU cluster usage is enabled.</td>
</tr>
<tr>
<td><code>tpu_use_sudo</code></td>
<td>Boolean</td>
<td>false</td>
<td>Indicates if sudo is required for TPU usage.</td>
</tr>
<tr>
<td><code>use_cpu</code></td>
<td>Boolean</td>
<td>false</td>
<td>Indicates if CPU is used instead of GPU/TPU.</td>
</tr>
</tbody>
</table>
<h2 id="text-generation">Text Generation</h2>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Data Type</th>
<th>Default Value</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>packing</code></td>
<td>bool</td>
<td>True</td>
<td>A boolean indicating whether packing is enabled or not.</td>
</tr>
<tr>
<td><code>dataset_text_field</code></td>
<td>str</td>
<td>'text'</td>
<td>The field in the dataset containing the text data.</td>
</tr>
<tr>
<td><code>max_seq_length</code></td>
<td>int</td>
<td>512</td>
<td>The maximum sequence length allowed for input text.</td>
</tr>
<tr>
<td><code>flash_attention2</code></td>
<td>bool</td>
<td>Fasle</td>
<td>Argument to indicate whether to use flash attention or not (Warning - most of the models don't support flash attention which might lead to unexpected behaviours)</td>
</tr>
</tbody>
</table>
<h2 id="text-classification">Text Classification</h2>
<p>nyuntam_adapt supports <ul>
     <li> <strong>Token Classification</strong> : <ul>
               <li> <strong>Named entity recognition (NER)</strong> : Find the entities (such as persons, locations, or organizations) in a sentence. This can be formulated as attributing a label to each token by having one class per entity and one class for “no entity.” </li>
               <li> <strong>Part-of-speech tagging (POS)</strong>: Mark each word in a sentence as corresponding to a particular part of speech (such as noun, verb, adjective, etc.). </li>
               <li> <strong>Chunking</strong>: Find the tokens that belong to the same entity. This task (which can be combined with POS or NER) can be formulated as attributing one label (usually B-) to any tokens that are at the beginning of a chunk, another label (usually I-) to tokens that are inside a chunk, and a third label (usually O) to tokens that don’t belong to any chunk.</li>
               </ul>
     <li> <strong>Text Classification</strong> : Classification of given text into 2 or more classes (examples - emotion recognition)</li>
     </ul></p>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Data Type</th>
<th>Default Value</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>subtask</code></td>
<td>str</td>
<td>None</td>
<td>The specific subtask associated with the model ("ner" ,"pos", "chunk", ). If subtask = None, then the task is classic text classification</td>
</tr>
</tbody>
</table>
<h2 id="summarization">Summarization</h2>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Data Type</th>
<th>Default Value</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>MAX_TRAIN_SAMPLES</code></td>
<td>int</td>
<td>1000</td>
<td>Maximum number of training samples</td>
</tr>
<tr>
<td><code>MAX_EVAL_SAMPLES</code></td>
<td>int</td>
<td>1000</td>
<td>Maximum number of evaluation samples</td>
</tr>
<tr>
<td><code>max_input_length</code></td>
<td>int</td>
<td>512</td>
<td>The maximum length allowed for input documents.</td>
</tr>
<tr>
<td><code>max_target_length</code></td>
<td>int</td>
<td>128</td>
<td>The maximum length allowed for generated summaries.</td>
</tr>
<tr>
<td><code>eval_metric</code></td>
<td>str</td>
<td>'rouge'</td>
<td>The evaluation metric used during training and evaluation (options: 'bleu', 'rouge').</td>
</tr>
<tr>
<td><code>generation_max_length</code></td>
<td>int</td>
<td>128</td>
<td>The maximum length allowed for generated text during prediction.</td>
</tr>
</tbody>
</table>
<h2 id="translation">Translation</h2>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Data Type</th>
<th>Default Value</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>max_input_length</code></td>
<td>int</td>
<td>128</td>
<td>The maximum length allowed for input sentences.</td>
</tr>
<tr>
<td><code>max_target_length</code></td>
<td>int</td>
<td>128</td>
<td>The maximum length allowed for translated sentences.</td>
</tr>
<tr>
<td><code>eval_metric</code></td>
<td>str</td>
<td>'rouge'</td>
<td>The evaluation metric used during training and evaluation (options: 'sacrebleu', 'rouge').</td>
</tr>
<tr>
<td><code>source_lang</code></td>
<td>str</td>
<td>'en'</td>
<td>The source language for translation (e.g., English).</td>
</tr>
<tr>
<td><code>target_lang</code></td>
<td>str</td>
<td>'ro'</td>
<td>The target language for translation (e.g., Romanian).</td>
</tr>
<tr>
<td><code>PREFIX</code></td>
<td>str</td>
<td>example -'translate English to Russian: '</td>
<td>For multi-task models like t5, prefix is attached during specific tasks</td>
</tr>
</tbody>
</table>
<h2 id="question-answering">Question Answering</h2>
<p>nyuntam_adapt support span detection in question answering.</p>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Data Type</th>
<th>Default Value</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>MAX_TRAIN_SAMPLES</code></td>
<td>int</td>
<td>1000</td>
<td>Maximum number of training samples</td>
</tr>
<tr>
<td><code>MAX_EVAL_SAMPLES</code></td>
<td>int</td>
<td>1000</td>
<td>Maximum number of evaluation samples</td>
</tr>
<tr>
<td><code>max_answer_length</code></td>
<td>int</td>
<td>30</td>
<td>The maximum length allowed for the generated answers.</td>
</tr>
<tr>
<td><code>max_length</code></td>
<td>int</td>
<td>384</td>
<td>The maximum length allowed for input documents.</td>
</tr>
<tr>
<td><code>doc_stride</code></td>
<td>int</td>
<td>128</td>
<td>The stride used when the context is too large and is split across several features</td>
</tr>
</tbody>
</table>
<h2 id="image-classification">Image Classification</h2>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Data Type</th>
<th>Default Value</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>load_model</code></td>
<td>bool</td>
<td>False</td>
<td>A boolean indicating whether to load a pre-trained model.</td>
</tr>
<tr>
<td><code>model_path</code></td>
<td>str</td>
<td>"densenet121"</td>
<td>The path or identifier of the pre-trained model to be loaded.</td>
</tr>
<tr>
<td><code>model_type</code></td>
<td>str</td>
<td>'densenet_timm'</td>
<td>The type of the loaded model (e.g., 'densenet_timm').</td>
</tr>
<tr>
<td><code>image_processor_path</code></td>
<td>str</td>
<td>'facebook/convnext-tiny-224'</td>
<td>The path or identifier of the image processor configuration.</td>
</tr>
</tbody>
</table>
<h2 id="object-detection">Object Detection</h2>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Datatype</th>
<th>Default Value</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>BEGIN</code></td>
<td>int</td>
<td>0</td>
<td>The epoch from which the learning rate scheduler starts</td>
</tr>
<tr>
<td><code>END</code></td>
<td>int</td>
<td>50</td>
<td>The epoch at which the learning rate scheduler stops</td>
</tr>
<tr>
<td><code>T_MAX</code></td>
<td>int</td>
<td>0</td>
<td>Maximum number of iterations. (Exclusive Parameter for CossineAnnealingLR scheduler)</td>
</tr>
<tr>
<td><code>WARMUP</code></td>
<td>bool</td>
<td>false</td>
<td>Flag to indicate whether to use wamrup iters or not</td>
</tr>
<tr>
<td><code>WARMUP_RATIO</code></td>
<td>float</td>
<td>0.1</td>
<td>The ratio of (wamrup learning rate)/(real learning rate)</td>
</tr>
<tr>
<td><code>WARMUP_ITERS</code></td>
<td>int</td>
<td>50</td>
<td>The number of warmup iterations</td>
</tr>
<tr>
<td><code>MILESTONES</code></td>
<td>list</td>
<td>[]</td>
<td>List of epoch indices in increagin order where the LR changes (exclusive parameter for MultiStepLR scheduler)</td>
</tr>
<tr>
<td><code>GAMMA</code></td>
<td>float</td>
<td>0.1</td>
<td>Multiplicative factor of learning rate decay.</td>
</tr>
<tr>
<td><code>amp</code></td>
<td>bool</td>
<td>False</td>
<td>Automatic mixed precision training.</td>
</tr>
<tr>
<td><code>auto_scale_lr</code></td>
<td>bool</td>
<td>False</td>
<td>Enable automatic scaling of learning rates.</td>
</tr>
<tr>
<td><code>cfg_options</code></td>
<td>bool or dict</td>
<td>None</td>
<td>Additional configuration options for the MMDET model. If True, it indicates the default options should be used.</td>
</tr>
<tr>
<td><code>train_ann_file</code></td>
<td>str</td>
<td>'train.json'</td>
<td>Annotation file for training in COCO format.</td>
</tr>
<tr>
<td><code>val_ann_file</code></td>
<td>str</td>
<td>'val.json'</td>
<td>Annotation file for validation in COCO format.</td>
</tr>
<tr>
<td><code>checkpoint_interval</code></td>
<td>int</td>
<td>5</td>
<td>Interval for saving checkpoints during training (in epochs).</td>
</tr>
</tbody>
</table>
<h2 id="instance-segmentation">Instance Segmentation</h2>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Datatype</th>
<th>Default Value</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>BEGIN</code></td>
<td>int</td>
<td>0</td>
<td>The epoch from which the learning rate scheduler starts</td>
</tr>
<tr>
<td><code>END</code></td>
<td>int</td>
<td>50</td>
<td>The epoch at which the learning rate scheduler stops</td>
</tr>
<tr>
<td><code>T_MAX</code></td>
<td>int</td>
<td>0</td>
<td>Maximum number of iterations. (Exclusive Parameter for CossineAnnealingLR scheduler)</td>
</tr>
<tr>
<td><code>WARMUP</code></td>
<td>bool</td>
<td>false</td>
<td>Flag to indicate whether to use wamrup iters or not</td>
</tr>
<tr>
<td><code>WARMUP_RATIO</code></td>
<td>float</td>
<td>0.1</td>
<td>The ratio of (wamrup learning rate)/(real learning rate)</td>
</tr>
<tr>
<td><code>WARMUP_ITERS</code></td>
<td>int</td>
<td>50</td>
<td>The number of warmup iterations</td>
</tr>
<tr>
<td><code>MILESTONES</code></td>
<td>list</td>
<td>[]</td>
<td>List of epoch indices in increagin order where the LR changes (exclusive parameter for MultiStepLR scheduler)</td>
</tr>
<tr>
<td><code>GAMMA</code></td>
<td>float</td>
<td>0.1</td>
<td>Multiplicative factor of learning rate decay.</td>
</tr>
<tr>
<td><code>amp</code></td>
<td>bool</td>
<td>False</td>
<td>Automatic mixed precision training.</td>
</tr>
<tr>
<td><code>auto_scale_lr</code></td>
<td>bool</td>
<td>False</td>
<td>Enable automatic scaling of learning rates.</td>
</tr>
<tr>
<td><code>cfg_options</code></td>
<td>bool or dict</td>
<td>None</td>
<td>Additional configuration options for the MMDET model. If True, it indicates the default options should be used.</td>
</tr>
<tr>
<td><code>train_ann_file</code></td>
<td>str</td>
<td>'train.txt'</td>
<td>Annotation file for training containing all the image names in train folder (without the extension)</td>
</tr>
<tr>
<td><code>val_ann_file</code></td>
<td>str</td>
<td>'val.txt'</td>
<td>Annotation file for training containing all the image names in test folder (without the extension)</td>
</tr>
<tr>
<td><code>checkpoint_interval</code></td>
<td>int</td>
<td>5</td>
<td>Interval for saving checkpoints during training (in epochs).</td>
</tr>
<tr>
<td><code>class_list</code></td>
<td>list</td>
<td>[]</td>
<td>List containing all the classes in the segmentation task</td>
</tr>
<tr>
<td><code>palette</code></td>
<td>list</td>
<td>[]</td>
<td>List of Lists containing the RGB value for each class</td>
</tr>
</tbody>
</table>
<h2 id="pose-detection">Pose Detection</h2>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Datatype</th>
<th>Default Value</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>BEGIN</code></td>
<td>int</td>
<td>0</td>
<td>The epoch from which the learning rate scheduler starts</td>
</tr>
<tr>
<td><code>END</code></td>
<td>int</td>
<td>50</td>
<td>The epoch at which the learning rate scheduler stops</td>
</tr>
<tr>
<td><code>T_MAX</code></td>
<td>int</td>
<td>0</td>
<td>Maximum number of iterations. (Exclusive Parameter for CossineAnnealingLR scheduler)</td>
</tr>
<tr>
<td><code>WARMUP</code></td>
<td>bool</td>
<td>false</td>
<td>Flag to indicate whether to use wamrup iters or not</td>
</tr>
<tr>
<td><code>WARMUP_RATIO</code></td>
<td>float</td>
<td>0.1</td>
<td>The ratio of (wamrup learning rate)/(real learning rate)</td>
</tr>
<tr>
<td><code>WARMUP_ITERS</code></td>
<td>int</td>
<td>50</td>
<td>The number of warmup iterations</td>
</tr>
<tr>
<td><code>MILESTONES</code></td>
<td>list</td>
<td>[]</td>
<td>List of epoch indices in increagin order where the LR changes (exclusive parameter for MultiStepLR scheduler)</td>
</tr>
<tr>
<td><code>GAMMA</code></td>
<td>float</td>
<td>0.1</td>
<td>Multiplicative factor of learning rate decay.</td>
</tr>
<tr>
<td><code>amp</code></td>
<td>bool</td>
<td>False</td>
<td>Automatic mixed precision training.</td>
</tr>
<tr>
<td><code>auto_scale_lr</code></td>
<td>bool</td>
<td>False</td>
<td>Enable automatic scaling of learning rates.</td>
</tr>
<tr>
<td><code>cfg_options</code></td>
<td>bool or dict</td>
<td>None</td>
<td>Additional configuration options for the MMDET model. If True, it indicates the default options should be used.</td>
</tr>
<tr>
<td><code>train_ann_file</code></td>
<td>str</td>
<td>'annotations/person_keypoints_val2017.json'</td>
<td>Annotation file for training in COCO-Pose format.</td>
</tr>
<tr>
<td><code>val_ann_file</code></td>
<td>str</td>
<td>'annotations/person_keypoints_val2017.json'</td>
<td>Annotation file for validation in COCO-Pose format.</td>
</tr>
<tr>
<td><code>checkpoint_interval</code></td>
<td>int</td>
<td>5</td>
<td>Interval for saving checkpoints during training (in epochs).</td>
</tr>
</tbody>
</table>







  
  






                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
      <div class="md-progress" data-md-component="progress" role="progressbar"></div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.instant", "navigation.instant.prefetch", "navigation.instant.progress", "navigation.tracking", "navigation.expand", "navigation.path", "toc.integrate", "navigation.top", "search.suggest", "search.highlight", "navigation.indexes"], "search": "../../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.1e8ae164.min.js"></script>
      
    
  </body>
</html>